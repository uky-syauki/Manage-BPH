{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 15:20:49.759625: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-27 15:20:49.817547: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-27 15:20:49.819009: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 15:20:51.115798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img/dzikri/dzikri.18.png\n",
      "img/dzikri/dzikri.12.png\n",
      "img/dzikri/dzikri.5.png\n",
      "img/dzikri/dzikri.19.png\n",
      "img/dzikri/dzikri.4.png\n",
      "img/dzikri/dzikri.7.png\n",
      "img/dzikri/dzikri.8.png\n",
      "img/dzikri/dzikri.10.png\n",
      "img/dzikri/dzikri.11.png\n",
      "img/dzikri/dzikri.44.png\n",
      "img/dzikri/dzikri.6.png\n",
      "img/dzikri/dzikri.13.png\n",
      "img/dzikri/dzikri.9.png\n",
      "img/dzikri/dzikri.3.png\n",
      "img/dzikri/dzikri.16.png\n",
      "img/dzikri/dzikri.17.png\n",
      "img/dzikri/dzikri.1.png\n",
      "img/dzikri/dzikri.2.png\n",
      "img/dzikri/dzikri.15.png\n",
      "img/dzikri/dzikri.20.png\n",
      "img/diva/diva.4.png\n",
      "img/diva/diva.1.png\n",
      "img/diva/diva.2.png\n",
      "img/diva/diva.14.png\n",
      "img/diva/diva.6.png\n",
      "img/diva/diva.17.png\n",
      "img/diva/diva.20.png\n",
      "img/diva/diva.3.png\n",
      "img/diva/diva.7.png\n",
      "img/diva/diva.12.png\n",
      "img/diva/diva.15.png\n",
      "img/diva/diva.18.png\n",
      "img/diva/diva.8.png\n",
      "img/diva/diva.16.png\n",
      "img/diva/diva.5.png\n",
      "img/diva/diva.9.png\n",
      "img/diva/diva.11.png\n",
      "img/diva/diva.19.png\n",
      "img/diva/diva.10.png\n",
      "img/diva/diva.13.png\n",
      "img/uki/uki.19.png\n",
      "img/uki/uki.14.png\n",
      "img/uki/uki.2.png\n",
      "img/uki/uki.5.png\n",
      "img/uki/uki.4.png\n",
      "img/uki/uki.15.png\n",
      "img/uki/uki.9.png\n",
      "img/uki/uki.20.png\n",
      "img/uki/uki.3.png\n",
      "img/uki/uki.6.png\n",
      "img/uki/uki.12.png\n",
      "img/uki/uki.10.png\n",
      "img/uki/uki.11.png\n",
      "img/uki/uki.18.png\n",
      "img/uki/uki.1.png\n",
      "img/uki/uki.17.png\n",
      "img/uki/uki.13.png\n",
      "img/uki/uki.16.png\n",
      "img/uki/uki.7.png\n",
      "img/uki/uki.8.png\n",
      "img/arini/arini.14.png\n",
      "img/arini/arini.12.png\n",
      "img/arini/arini.10.png\n",
      "img/arini/arini.7.png\n",
      "img/arini/arini.4.png\n",
      "img/arini/arini.16.png\n",
      "img/arini/arini.19.png\n",
      "img/arini/arini.9.png\n",
      "img/arini/arini.17.png\n",
      "img/arini/arini.6.png\n",
      "img/arini/arini.5.png\n",
      "img/arini/arini.13.png\n",
      "img/arini/arini.3.png\n",
      "img/arini/arini.2.png\n",
      "img/arini/arini.18.png\n",
      "img/arini/arini.15.png\n",
      "img/arini/arini.11.png\n",
      "img/arini/arini.8.png\n",
      "img/arini/arini.20.png\n",
      "img/arini/arini.1.png\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir('img'):\n",
    "    for foto in os.listdir(f'img/{folder}'):\n",
    "        print(f'img/{folder}/{foto}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m images, labels\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m dataset_folder \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdataset/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m images, labels \u001b[39m=\u001b[39m load_images_from_folder(dataset_folder)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(images, labels, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# Inisialisasi model\u001b[39;00m\n",
      "\u001b[1;32m/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m labels \u001b[39m=\u001b[39m label_encoder\u001b[39m.\u001b[39mfit_transform(labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m labels \u001b[39m=\u001b[39m to_categorical(labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint\u001b[39m(labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ahmad/opencvPro/App-BPH-Manage/ML.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mreturn\u001b[39;00m images, labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/src/utils/np_utils.py:71\u001b[0m, in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     69\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m num_classes:\n\u001b[0;32m---> 71\u001b[0m     num_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmax(y) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     72\u001b[0m n \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m categorical \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((n, num_classes), dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2791\u001b[0m, in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[1;32m   2676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2677\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2678\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2679\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[1;32m   2680\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2789\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[1;32m   2790\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2791\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[1;32m   2792\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade/face_detect.xml')\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_encoder = LabelEncoder()\n",
    "    for subfolder in os.listdir(folder):\n",
    "        # subfolder_path = os.path.join(folder, subfolder)\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            img_path = os.path.join(subfolder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Ubah ke skala abu-abu jika perlu\n",
    "                wajah = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "                for (x, y, w, h) in wajah:\n",
    "                    img = img[y:y+h, x:x+w] / 255.0\n",
    "                    img = cv2.resize(img, (128, 128))\n",
    "                    images.append(img)\n",
    "                    labels.append(subfolder)  # Label adalah nama subfolder\n",
    "    print(labels)\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    print(labels)\n",
    "    return images, labels\n",
    "\n",
    "dataset_folder = 'dataset/'\n",
    "images, labels = load_images_from_folder(dataset_folder)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inisialisasi model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Tambahkan lapisan konvolusi pertama\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Tambahkan lapisan konvolusi kedua\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Tambahkan lapisan konvolusi ketiga (opsional)\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Lapisan Flatten untuk mengubah matriks menjadi vektor\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Tambahkan lapisan fully connected pertama\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Tambahkan lapisan fully connected kedua (output layer)\n",
    "num_classes = 4\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))  # Ganti num_classes dengan jumlah kelas identitas wajah\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Jika ini adalah masalah klasifikasi\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Tampilkan ringkasan model\n",
    "model.summary()\n",
    "model.save('nama_model.h5')\n",
    "\n",
    "# Konversi label menjadi one-hot encoding\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_encoded = label_binarizer.fit_transform(y_train)\n",
    "y_test_encoded = label_binarizer.transform(y_test)\n",
    "\n",
    "desired_size = (128, 128)\n",
    "\n",
    "# Resizing gambar-gambar dalam dataset\n",
    "X_train_resized = [cv2.resize(img, desired_size) for img in X_train]\n",
    "X_test_resized = [cv2.resize(img, desired_size) for img in X_test]\n",
    "\n",
    "\n",
    "# Konversi data gambar dan label menjadi array NumPy\n",
    "X_train_array = np.array(X_train_resized)\n",
    "X_test_array = np.array(X_test_resized)\n",
    "\n",
    "# Reshape data untuk memenuhi format yang diperlukan oleh model (sesuai dengan input_shape)\n",
    "X_train_array = X_train_array.reshape(-1, 128, 128, 1)  # Ganti dimensi sesuai dengan ukuran gambar\n",
    "X_test_array = X_test_array.reshape(-1, 128, 128, 1)\n",
    "\n",
    "# Normalisasi nilai piksel ke rentang [0, 1]\n",
    "X_train_array = X_train_array / 255.0\n",
    "X_test_array = X_test_array / 255.0\n",
    "\n",
    "# Pelatihan model\n",
    "history = model.fit(\n",
    "    X_train_array, y_train_encoded,\n",
    "    epochs=10,  # Ganti jumlah epoch sesuai kebutuhan\n",
    "    batch_size=32,  # Ganti ukuran batch sesuai kebutuhan\n",
    "    validation_data=(X_test_array, y_test_encoded)\n",
    ")\n",
    "\n",
    "# Evaluasi model\n",
    "loss, accuracy = model.evaluate(X_test_array, y_test_encoded)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "\n",
    "# Prediksi kelas untuk dataset pengujian\n",
    "y_pred = model.predict(X_test_array)\n",
    "\n",
    "# Mengambil indeks kelas dengan probabilitas tertinggi sebagai prediksi\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Mengambil indeks kelas dengan probabilitas tertinggi sebagai label sebenarnya\n",
    "y_true = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Menghitung akurasi\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "print(f\"Akurasi: {accuracy}\")\n",
    "\n",
    "# Membuat laporan klasifikasi\n",
    "classification_rep = classification_report(y_true, y_pred_classes)\n",
    "print(\"Laporan Klasifikasi:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Menghitung dan menampilkan matriks kebingungan (confusion matrix)\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"Matriks Kebingungan:\")\n",
    "print(confusion_mtx)\n",
    "\n",
    "\n",
    "# Import library yang diperlukan\n",
    "\n",
    "# Memuat model yang sudah dilatih\n",
    "model = load_model('nama_model.h5')  # Ganti 'nama_model.h5' dengan nama model yang sudah Anda simpan\n",
    "\n",
    "# Membaca gambar yang akan diprediksi\n",
    "input_image_path = 'imgtest/diva/diva.21.png'  # Ganti dengan path gambar input Anda\n",
    "input_image = cv2.imread(input_image_path)\n",
    "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)  # Ubah ke skala abu-abu jika diperlukan\n",
    "input_image = cv2.resize(input_image, (128, 128))  # Sesuaikan dengan ukuran yang digunakan saat pelatihan\n",
    "input_image = input_image / 255.0  # Normalisasi\n",
    "\n",
    "# Lakukan inferensi\n",
    "input_image = np.expand_dims(input_image, axis=0)  # Menambahkan dimensi batch\n",
    "predictions = model.predict(input_image)\n",
    "\n",
    "# Mengambil kelas dengan probabilitas tertinggi sebagai prediksi\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Konversi indeks kelas menjadi label atau hasil yang sesuai dengan aplikasi Anda\n",
    "# Contoh: jika Anda memiliki dictionary yang memetakan indeks ke label\n",
    "# class_labels = {0: 'Label 0', 1: 'Label 1', 2: 'Label 2'} \n",
    " # Ganti dengan label-label Anda\n",
    "\n",
    "class_labels = {}\n",
    "for i, isi in enumerate(os.listdir('img/')):\n",
    "    class_labels[i] = isi\n",
    "\n",
    "print(class_labels)\n",
    "predicted_label = class_labels[predicted_class[0]]\n",
    "\n",
    "# Cetak hasil prediksi\n",
    "print(f'Hasil prediksi: {predicted_label}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini']\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade/face_detect.xml')\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_encoder = LabelEncoder()\n",
    "    for subfolder in os.listdir(folder):\n",
    "        # subfolder_path = os.path.join(folder, subfolder)\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            img_path = os.path.join(subfolder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Ubah ke skala abu-abu jika perlu\n",
    "                wajah = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "                for (x, y, w, h) in wajah:\n",
    "                    img = cv2.resize(img[y:y+h, x:x+w], (100, 100))\n",
    "                    img = img / 255.0\n",
    "    #                 cv2.imshow(\"gambar\", img)\n",
    "    #                 cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "                    images.append(img)\n",
    "                    labels.append(subfolder)  # Label adalah nama subfolder\n",
    "    print(labels)\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    print(labels)\n",
    "    return images, labels\n",
    "\n",
    "dataset_folder = 'img/'\n",
    "images, labels = load_images_from_folder(dataset_folder)\n",
    "\n",
    "# load_images_from_folder(dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 98, 98, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 49, 49, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 23, 23, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 10, 10, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               6554112   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6648836 (25.36 MB)\n",
      "Trainable params: 6648836 (25.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/opencvPro/App-BPH-Manage/venv/lib/python3.9/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Tambahkan lapisan konvolusi pertama\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Tambahkan lapisan konvolusi kedua\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Tambahkan lapisan konvolusi ketiga (opsional)\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Lapisan Flatten untuk mengubah matriks menjadi vektor\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Tambahkan lapisan fully connected pertama\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Tambahkan lapisan fully connected kedua (output layer)\n",
    "num_classes = 4\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))  # Ganti num_classes dengan jumlah kelas identitas wajah\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Jika ini adalah masalah klasifikasi\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Tampilkan ringkasan model\n",
    "model.summary()\n",
    "model.save('nama_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 721ms/step - loss: 1.3871 - accuracy: 0.2812 - val_loss: 1.3881 - val_accuracy: 0.1875\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 600ms/step - loss: 1.3861 - accuracy: 0.2656 - val_loss: 1.3966 - val_accuracy: 0.1875\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 1.3882 - accuracy: 0.2656 - val_loss: 1.4085 - val_accuracy: 0.1875\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 1.3830 - accuracy: 0.2656 - val_loss: 1.4110 - val_accuracy: 0.1875\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 488ms/step - loss: 1.3827 - accuracy: 0.2656 - val_loss: 1.4178 - val_accuracy: 0.1250\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 1.3829 - accuracy: 0.2812 - val_loss: 1.4194 - val_accuracy: 0.1250\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 1.3822 - accuracy: 0.2812 - val_loss: 1.4283 - val_accuracy: 0.1250\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 410ms/step - loss: 1.3822 - accuracy: 0.2812 - val_loss: 1.4257 - val_accuracy: 0.1250\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 402ms/step - loss: 1.3806 - accuracy: 0.2812 - val_loss: 1.4291 - val_accuracy: 0.1250\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 388ms/step - loss: 1.3826 - accuracy: 0.2812 - val_loss: 1.4381 - val_accuracy: 0.1250\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 1.4381 - accuracy: 0.1250\n",
      "Loss: 1.4381362199783325, Accuracy: 0.125\n"
     ]
    }
   ],
   "source": [
    "# Konversi label menjadi one-hot encoding\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_encoded = label_binarizer.fit_transform(y_train)\n",
    "y_test_encoded = label_binarizer.transform(y_test)\n",
    "\n",
    "desired_size = (100, 100)\n",
    "\n",
    "# Resizing gambar-gambar dalam dataset\n",
    "X_train_resized = [cv2.resize(img, desired_size) for img in X_train]\n",
    "X_test_resized = [cv2.resize(img, desired_size) for img in X_test]\n",
    "\n",
    "\n",
    "# Konversi data gambar dan label menjadi array NumPy\n",
    "X_train_array = np.array(X_train_resized)\n",
    "X_test_array = np.array(X_test_resized)\n",
    "\n",
    "# Reshape data untuk memenuhi format yang diperlukan oleh model (sesuai dengan input_shape)\n",
    "# X_train_array = X_train_array.reshape(-1, 100, 100, 1)  # Ganti dimensi sesuai dengan ukuran gambar\n",
    "# X_test_array = X_test_array.reshape(-1, 100, 100, 1)\n",
    "\n",
    "# Normalisasi nilai piksel ke rentang [0, 1]\n",
    "X_train_array = X_train_array / 255.0\n",
    "X_test_array = X_test_array / 255.0\n",
    "\n",
    "# Pelatihan model\n",
    "history = model.fit(\n",
    "    X_train_array, y_train_encoded,\n",
    "    epochs=10,  # Ganti jumlah epoch sesuai kebutuhan\n",
    "    batch_size=32,  # Ganti ukuran batch sesuai kebutuhan\n",
    "    validation_data=(X_test_array, y_test_encoded)\n",
    ")\n",
    "\n",
    "# Evaluasi model\n",
    "loss, accuracy = model.evaluate(X_test_array, y_test_encoded)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "Akurasi: 0.125\n",
      "Laporan Klasifikasi:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.12      1.00      0.22         2\n",
      "\n",
      "    accuracy                           0.12        16\n",
      "   macro avg       0.03      0.25      0.06        16\n",
      "weighted avg       0.02      0.12      0.03        16\n",
      "\n",
      "Matriks Kebingungan:\n",
      "[[0 0 0 3]\n",
      " [0 0 0 6]\n",
      " [0 0 0 5]\n",
      " [0 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmad/opencvPro/App-BPH-Manage/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ahmad/opencvPro/App-BPH-Manage/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ahmad/opencvPro/App-BPH-Manage/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prediksi kelas untuk dataset pengujian\n",
    "y_pred = model.predict(X_test_array)\n",
    "\n",
    "# Mengambil indeks kelas dengan probabilitas tertinggi sebagai prediksi\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Mengambil indeks kelas dengan probabilitas tertinggi sebagai label sebenarnya\n",
    "y_true = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Menghitung akurasi\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "print(f\"Akurasi: {accuracy}\")\n",
    "\n",
    "# Membuat laporan klasifikasi\n",
    "classification_rep = classification_report(y_true, y_pred_classes)\n",
    "print(\"Laporan Klasifikasi:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Menghitung dan menampilkan matriks kebingungan (confusion matrix)\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"Matriks Kebingungan:\")\n",
    "print(confusion_mtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe37c584280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "{0: 'dzikri', 1: 'diva', 2: 'uki', 3: 'arini'}\n",
      "Hasil prediksi: arini\n"
     ]
    }
   ],
   "source": [
    "# Import library yang diperlukan\n",
    "\n",
    "# Memuat model yang sudah dilatih\n",
    "model = load_model('nama_model.h5')  # Ganti 'nama_model.h5' dengan nama model yang sudah Anda simpan\n",
    "\n",
    "# Membaca gambar yang akan diprediksi\n",
    "input_image_path = 'imgtest/diva/diva.21.png'  # Ganti dengan path gambar input Anda\n",
    "input_image = cv2.imread(input_image_path)\n",
    "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)  # Ubah ke skala abu-abu jika diperlukan\n",
    "input_image = cv2.resize(input_image, (100, 100))  # Sesuaikan dengan ukuran yang digunakan saat pelatihan\n",
    "# cv2.imshow(\"Entah\", input_image)\n",
    "\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "\n",
    "input_image = input_image / 255.0  # Normalisasi\n",
    "\n",
    "# Lakukan inferensi\n",
    "input_image = np.expand_dims(input_image, axis=0)  # Menambahkan dimensi batch\n",
    "predictions = model.predict(input_image)\n",
    "# print(predicted_class)\n",
    "\n",
    "# Mengambil kelas dengan probabilitas tertinggi sebagai prediksi\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Konversi indeks kelas menjadi label atau hasil yang sesuai dengan aplikasi Anda\n",
    "# Contoh: jika Anda memiliki dictionary yang memetakan indeks ke label\n",
    "# class_labels = {0: 'Label 0', 1: 'Label 1', 2: 'Label 2'} \n",
    " # Ganti dengan label-label Anda\n",
    "\n",
    "class_labels = {}\n",
    "for i, isi in enumerate(os.listdir('img/')):\n",
    "    class_labels[i] = isi\n",
    "\n",
    "print(class_labels)\n",
    "# print(predicted_class)\n",
    "predicted_label = class_labels[predicted_class[0]]\n",
    "\n",
    "# Cetak hasil prediksi\n",
    "print(f'Hasil prediksi: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# def ganti_nama(lama, baru):\n",
    "#     os.rename(lama, baru)\n",
    "\n",
    "\n",
    "# lsdir = os.listdir('img')\n",
    "# print(lsdir)\n",
    "# jumlah = 0\n",
    "# hitung = 0\n",
    "# for isi in lsdir:\n",
    "#     lspath = os.listdir(f'img/{isi}')\n",
    "#     print(len(lspath), isi)\n",
    "#     jumlah += len(lspath)\n",
    "#     hitung += 1\n",
    "\n",
    "\n",
    "\n",
    "# lsdir = os.listdir('imgtest')\n",
    "# print(lsdir)\n",
    "# jumlah = 0\n",
    "# hitung = 0\n",
    "# for isi in lsdir:\n",
    "#     lspath = os.listdir(f'imgtest/{isi}')\n",
    "#     print(len(lspath), isi)\n",
    "#     jumlah += len(lspath)\n",
    "#     hitung += 1\n",
    "\n",
    "\n",
    "\n",
    "    # jumlah = 1\n",
    "    # for upath in lspath:\n",
    "\n",
    "        # ganti_nama(f'img/{isi}/{upath}', f\"img/{isi}/{isi}.{jumlah}.png\")\n",
    "        # jumlah += 1\n",
    "\n",
    "    # jumlah = 1\n",
    "    # for upath in lspath:\n",
    "\n",
    "        # ganti_nama(f'img/{isi}/{upath}', f\"img/{isi}/{isi}.{jumlah}.png\")\n",
    "        # jumlah += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_dataset = 'dataset/'\n",
    "# path_img = 'img/'\n",
    "\n",
    "# face_cascade = cv.CascadeClassifier('cascade/face_detect.xml')\n",
    "# eye_cascade = cv.CascadeClassifier('cascade/eye_detect.xml')\n",
    "\n",
    "# while True:\n",
    "#     img = cv.imread(f'{path_img}uki/uki.1.png')\n",
    "#     gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#     wajah = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "#     for (x, y, w, h) in wajah:\n",
    "#         cv.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "#         cv.imwrite(f\"{path_dataset}uki.1.png\", gray[y:y+h, x:x+w])\n",
    "#     cv.imshow('img',img)\n",
    "#     k = cv.waitKey(0)\n",
    "#     if k == 27:\n",
    "#         break\n",
    "\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsdir = os.listdir('img')\n",
    "# print(lsdir)\n",
    "# label_names = [\"person1\", \"person2\", \"person3\"]\n",
    "# for labelid, labelname in enumerate(label_names):\n",
    "#     print(f\"id: {labelid} / nama: {labelname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_dataset = 'dataset/'\n",
    "# path_img = 'img/'\n",
    "\n",
    "# face_cascade = cv.CascadeClassifier('cascade/face_detect.xml')\n",
    "# eye_cascade = cv.CascadeClassifier('cascade/eye_detect.xml')\n",
    "\n",
    "# for path_user in os.listdir(path_img):\n",
    "#     if not os.path.exists(f'{path_dataset}{path_user}'):\n",
    "#         os.mkdir(f'{path_dataset}{path_user}')\n",
    "#     for foto in os.listdir(f\"{path_img}{path_user}\"):\n",
    "#         img = cv.imread(f\"{path_img}{path_user}/{foto}\")\n",
    "#         gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "#         wajah = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "#         for (x, y, w, h) in wajah:\n",
    "#             cv.imwrite(f'{path_dataset}{path_user}/{foto}', gray[y:y+h, x:x+w])\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import cv\n",
    "# # import numpy as np\n",
    "\n",
    "# # Path ke dataset wajah palsu (contoh)\n",
    "# # path_dataset = \"dataset/\"\n",
    "\n",
    "# # Inisialisasi array untuk menyimpan gambar dan label\n",
    "# X = []  # Array gambar wajah\n",
    "# y = []  # Array label\n",
    "\n",
    "# # Mendefinisikan daftar nama label yang sesuai dengan setiap subfolder dalam dataset\n",
    "# label_names = os.listdir(path_dataset)\n",
    "\n",
    "# target_size = (128, 128)\n",
    "\n",
    "# # Loop melalui setiap label (subfolder) dalam dataset\n",
    "# for label_id, label_name in enumerate(label_names):\n",
    "#     label_path = f\"{path_dataset}{label_name}/\"\n",
    "\n",
    "#     # Loop melalui setiap gambar dalam subfolder\n",
    "#     for image_filename in os.listdir(label_path):\n",
    "#         image_path = os.path.join(label_path, image_filename)\n",
    "#         print(image_path)\n",
    "\n",
    "#         # Membaca gambar dengan OpenCV\n",
    "#         image = cv.imread(image_path)\n",
    "#         image = cv.resize(image, target_size)\n",
    "\n",
    "#         # Mengubah gambar menjadi skala abu-abu jika perlu\n",
    "#         if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "#             image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "#         # Normalisasi intensitas piksel ke rentang [0, 1]\n",
    "#         image = image / 255.0\n",
    "\n",
    "#         # Menambahkan gambar dan label ke dalam array\n",
    "#         X.append(image)\n",
    "#         y.append(label_id)\n",
    "\n",
    "# # Mengubah array gambar dan label menjadi array NumPy\n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "# # Sekarang Anda memiliki dataset wajah dalam 'X' (gambar) dan 'y' (label)\n",
    "# # Anda dapat melanjutkan dengan melatih model pengenalan wajah dengan dataset ini.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "dzikri\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "diva\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "uki\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "arini\n",
      "['dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'dzikri', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'diva', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'uki', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini', 'arini']\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascade/face_detect.xml')\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    for subfolder in os.listdir(folder):\n",
    "        # subfolder_path = os.path.join(folder, subfolder)\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            img_path = os.path.join(subfolder_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Ubah ke skala abu-abu jika perlu\n",
    "                wajah = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "                for (x, y, w, h) in wajah:\n",
    "                    img = cv2.resize(img[y:y+h, x:x+w], (100, 100))\n",
    "                    img = img / 255.0\n",
    "    #                 cv2.imshow(\"gambar\", img)\n",
    "    #                 cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "                    images.append(img)\n",
    "                    print(subfolder)\n",
    "                    labels.append(subfolder)  # Label adalah nama subfolder\n",
    "    print(labels)\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "    labels = to_categorical(labels)\n",
    "    print(labels)\n",
    "    return images, labels\n",
    "\n",
    "dataset_folder = 'img/'\n",
    "images, labels = load_images_from_folder(dataset_folder)\n",
    "\n",
    "# load_images_from_folder(dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data pelatihan: 128\n",
      "Jumlah data pengujian: 33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_array = np.array(X_train)\n",
    "X_test_array = np.array(X_test)\n",
    "\n",
    "X_train_array = X_train_array.reshape(-1, 100, 100, 1)\n",
    "X_test_array = X_test_array.reshape(-1, 100, 100, 1)\n",
    "\n",
    "X_train_array = X_train_array / 255.0\n",
    "X_test_array = X_test_array / 255.0\n",
    "\n",
    "print(f\"Jumlah data pelatihan: {len(X_train)}\")\n",
    "print(f\"Jumlah data pengujian: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_36 (Conv2D)          (None, 98, 98, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPooli  (None, 49, 49, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPooli  (None, 23, 23, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 33856)             0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               4333696   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4353028 (16.61 MB)\n",
      "Trainable params: 4353028 (16.61 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# Inisialisasi model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Tambahkan lapisan konvolusi pertama\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Tambahkan lapisan konvolusi kedua\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "# Tambahkan lapisan konvolusi ketiga (opsional)\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "# Lapisan Flatten untuk mengubah matriks menjadi vektor\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Tambahkan lapisan fully connected pertama\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Tambahkan lapisan fully connected kedua (output layer)\n",
    "num_classes = 4  # Ganti dengan jumlah kelas yang sesuai dengan tugas Anda\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',  # Jika ini adalah masalah klasifikasi\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Tampilkan ringkasan model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step\n",
      "Akurasi: 0.9090909090909091\n",
      "Presisi: 0.9235209235209235\n",
      "Recall: 0.9090909090909091\n",
      "F1-Score: 0.9084787266605449\n",
      "Laporan Klasifikasi:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92         7\n",
      "           1       0.86      1.00      0.92         6\n",
      "           2       1.00      0.80      0.89        10\n",
      "           3       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.91        33\n",
      "   macro avg       0.92      0.91      0.91        33\n",
      "weighted avg       0.92      0.91      0.91        33\n",
      "\n",
      "Matriks Kebingungan:\n",
      "[[ 6  1  0  0]\n",
      " [ 0  6  0  0]\n",
      " [ 0  0  8  2]\n",
      " [ 0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Encode label pada y_test\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_test_encoded = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "# Evaluasi model pada dataset pengujian\n",
    "y_pred = model.predict(X_test_array)\n",
    "\n",
    "# Mengambil indeks kelas dengan probabilitas tertinggi sebagai prediksi\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Mengambil indeks kelas dengan probabilitas tertinggi sebagai label sebenarnya\n",
    "y_true = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Menghitung akurasi\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "print(f\"Akurasi: {accuracy}\")\n",
    "\n",
    "# Menghitung presisi, recall, dan F1-score\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f\"Presisi: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "\n",
    "# Membuat laporan klasifikasi\n",
    "classification_rep = classification_report(y_true, y_pred_classes)\n",
    "print(\"Laporan Klasifikasi:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Menghitung dan menampilkan matriks kebingungan (confusion matrix)\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"Matriks Kebingungan:\")\n",
    "print(confusion_mtx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 167ms/step - loss: 0.1049 - accuracy: 0.9844 - val_loss: 0.2599 - val_accuracy: 0.9091\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.0923 - accuracy: 1.0000 - val_loss: 0.2611 - val_accuracy: 0.8788\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9091\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 0.0687 - accuracy: 0.9922 - val_loss: 0.2102 - val_accuracy: 0.9091\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.0521 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9091\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 0.0486 - accuracy: 0.9922 - val_loss: 0.1869 - val_accuracy: 0.9394\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 1s 136ms/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9394\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.0371 - accuracy: 0.9922 - val_loss: 0.2145 - val_accuracy: 0.9394\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 0.9394\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9394\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.1623 - val_accuracy: 0.9394\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9394\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9394\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1644 - val_accuracy: 0.9394\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9394\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.1631 - val_accuracy: 0.9394\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9394\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9394\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9394\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1649 - val_accuracy: 0.9394\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1649 - accuracy: 0.9394\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_array, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_test_array, y_test)\n",
    ")\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_array, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "Hasil prediksi: dzikri\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Memuat gambar yang akan diuji\n",
    "input_image_path = 'img/dzikri/dzikri.10.png'  # Ganti dengan path gambar input Anda\n",
    "input_image = cv2.imread(input_image_path)  # Pastikan sesuai dengan preprocessing Anda\n",
    "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY) # Normalisasi nilai piksel ke rentang [0, 1]\n",
    "\n",
    "wajah = face_cascade.detectMultiScale(input_image, 1.1, 5) # Reshape gambar sesuai dengan format input model\n",
    "for (x, y, w, h) in wajah:\n",
    "    input_image = input_image[y:y+h, x:x+w]\n",
    "\n",
    "input_image = cv2.resize(input_image, (100, 100))\n",
    "input_image = input_image.astype('float32') / 255.0 # input_image = input_image / 255.0\n",
    "\n",
    "input_image = np.expand_dims(input_image, axis=0)  # Menambahkan dimensi batch\n",
    "predictions = model.predict(input_image) # Melakukan inferensi menggunakan model CNN\n",
    "\n",
    "predicted_class = np.argmax(predictions, axis=1) # Mengambil kelas dengan probabilitas tertinggi sebagai prediksi\n",
    "class_labels = {0:'arini', 1:'diva', 2:'dzikri',3:'uki'}  # Gantilah dengan label-label Anda\n",
    "\n",
    "# Cetak hasil prediksi\n",
    "print(f'Hasil prediksi: {class_labels[predicted_class[0]]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "Hasil prediksi: arini\n"
     ]
    }
   ],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# Memuat model CNN yang telah dilatih\n",
    "model_filename = 'nama_model.h5'  # Ganti dengan nama file model Anda\n",
    "# model = load_model(model_filename)\n",
    "\n",
    "# Memuat gambar yang akan diuji\n",
    "input_image_path = 'imgtest/diva/diva.23.png'  # Ganti dengan path gambar input Anda\n",
    "input_image = cv2.imread(input_image_path, cv2.IMREAD_GRAYSCALE)  # Pastikan sesuai dengan preprocessing Anda\n",
    "\n",
    "# Normalisasi nilai piksel ke rentang [0, 1]\n",
    "input_image = input_image.astype('float32') / 255.0\n",
    "\n",
    "input_image = cv2.resize(input_image, (100,100))\n",
    "\n",
    "# Reshape gambar sesuai dengan format input model\n",
    "input_image = np.expand_dims(input_image, axis=0)  # Menambahkan dimensi batch\n",
    "\n",
    "# Melakukan inferensi menggunakan model CNN\n",
    "predictions = model.predict(input_image)\n",
    "\n",
    "# Mengambil kelas dengan probabilitas tertinggi sebagai prediksi\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Konversi indeks kelas menjadi label atau hasil yang sesuai dengan aplikasi Anda\n",
    "# Contoh: jika Anda memiliki dictionary yang memetakan indeks ke label\n",
    "# class_labels = {0: 'Label 0', 1: 'Label 1', 2: 'Label 2'} \n",
    " # Ganti dengan label-label Anda\n",
    "\n",
    "class_labels = {0:'dzikri', 1:'diva', 2:'uki',3:'arini'}  # Gantilah dengan label-label Anda\n",
    "predicted_label = class_labels[predicted_class[0]]\n",
    "\n",
    "# Cetak hasil prediksi\n",
    "print(f'Hasil prediksi: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def uji_img(path_foto):\n",
    "    # Memuat gambar yang akan diuji\n",
    "    input_image_path = path_foto #'img/dzikri/dzikri.10.png'  # Ganti dengan path gambar input Anda\n",
    "    input_image = cv2.imread(input_image_path)  # Pastikan sesuai dengan preprocessing Anda\n",
    "    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY) # Normalisasi nilai piksel ke rentang [0, 1]\n",
    "\n",
    "    wajah = face_cascade.detectMultiScale(input_image, 1.1, 5) # Reshape gambar sesuai dengan format input model\n",
    "    for (x, y, w, h) in wajah:\n",
    "        input_image = input_image[y:y+h, x:x+w]\n",
    "\n",
    "    input_image = cv2.resize(input_image, (100, 100))\n",
    "    input_image = input_image.astype('float32') / 255.0 # input_image = input_image / 255.0\n",
    "\n",
    "    input_image = np.expand_dims(input_image, axis=0)  # Menambahkan dimensi batch\n",
    "    predictions = model.predict(input_image) # Melakukan inferensi menggunakan model CNN\n",
    "\n",
    "    predicted_class = np.argmax(predictions, axis=1) # Mengambil kelas dengan probabilitas tertinggi sebagai prediksi\n",
    "    class_labels = {0:'arini', 1:'diva', 2:'dzikri',3:'uki'}  # Gantilah dengan label-label Anda\n",
    "\n",
    "    # Cetak hasil prediksi\n",
    "    print(f'Hasil prediksi: {class_labels[predicted_class[0]]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 uki.19.png\n",
      "1 dzikri.5.png\n",
      "2 dzikri.4.png\n",
      "3 dzikri.6.png\n",
      "4 uki.20.png\n",
      "5 uki.18.png\n",
      "6 dzikri.3.png\n",
      "7 uki.17.png\n",
      "8 uki.16.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Hasil prediksi: uki\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Hasil prediksi: dzikri\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Hasil prediksi: dzikri\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Hasil prediksi: dzikri\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Hasil prediksi: uki\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Hasil prediksi: uki\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Hasil prediksi: dzikri\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "Hasil prediksi: uki\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Hasil prediksi: uki\n"
     ]
    }
   ],
   "source": [
    "path = 'imageTes/randomIMG'\n",
    "for i, isi in enumerate(os.listdir(path)):\n",
    "    print(i, isi)\n",
    "for foto in os.listdir(path):\n",
    "    uji_img(os.path.join(path, foto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img/dzikri/dzikri.18.png img/dzikri/dzikri.18.png\n",
      "img/dzikri/dzikri.12.png img/dzikri/dzikri.12.png\n",
      "img/dzikri/dzikri.5.png img/dzikri/dzikri.5.png\n",
      "img/dzikri/dzikri.19.png img/dzikri/dzikri.19.png\n",
      "img/dzikri/dzikri.4.png img/dzikri/dzikri.4.png\n",
      "img/dzikri/dzikri.7.png img/dzikri/dzikri.7.png\n",
      "img/dzikri/dzikri.8.png img/dzikri/dzikri.8.png\n",
      "img/dzikri/dzikri.10.png img/dzikri/dzikri.10.png\n",
      "img/dzikri/dzikri.11.png img/dzikri/dzikri.11.png\n",
      "img/dzikri/dzikri.44.png img/dzikri/dzikri.44.png\n",
      "img/dzikri/dzikri.6.png img/dzikri/dzikri.6.png\n",
      "img/dzikri/dzikri.13.png img/dzikri/dzikri.13.png\n",
      "img/dzikri/dzikri.9.png img/dzikri/dzikri.9.png\n",
      "img/dzikri/dzikri.3.png img/dzikri/dzikri.3.png\n",
      "img/dzikri/dzikri.16.png img/dzikri/dzikri.16.png\n",
      "img/dzikri/dzikri.17.png img/dzikri/dzikri.17.png\n",
      "img/dzikri/dzikri.1.png img/dzikri/dzikri.1.png\n",
      "img/dzikri/dzikri.2.png img/dzikri/dzikri.2.png\n",
      "img/dzikri/dzikri.15.png img/dzikri/dzikri.15.png\n",
      "img/dzikri/dzikri.20.png img/dzikri/dzikri.20.png\n"
     ]
    }
   ],
   "source": [
    "path = 'img/dzikri/'\n",
    "for foto in os.listdir(path):\n",
    "    img_path = os.path.join(path, foto)\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    wajah = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "    for (x, y, w, h) in wajah:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 1)\n",
    "        print(img_path, end=\" \")\n",
    "    print(img_path)\n",
    "    cv2.imshow('Hello',img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
